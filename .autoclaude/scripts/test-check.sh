#!/bin/bash
# Test Check
# Runs all tests and ensures they pass
# Auto-generated by AutoClaude

set -euo pipefail

# Initialize arrays
declare -a errors=()
declare -a test_commands=()

# Detect test framework and set commands
if [ -f "package.json" ]; then
    # Node.js project
    if command -v npm &> /dev/null; then
        # Check for test script in package.json
        if command -v jq &> /dev/null && jq -e '.scripts.test' package.json &> /dev/null; then
            test_commands+=("npm test")
        fi
    fi
    if command -v yarn &> /dev/null && [ -f "yarn.lock" ]; then
        test_commands+=("yarn test")
    fi
    if command -v pnpm &> /dev/null && [ -f "pnpm-lock.yaml" ]; then
        test_commands+=("pnpm test")
    fi
elif [ -f "Cargo.toml" ]; then
    # Rust project
    test_commands+=("cargo test")
elif [ -f "go.mod" ]; then
    # Go project
    test_commands+=("go test ./...")
elif [ -f "pom.xml" ]; then
    # Maven project
    test_commands+=("mvn test")
elif [ -f "build.gradle" ] || [ -f "build.gradle.kts" ]; then
    # Gradle project
    test_commands+=("gradle test")
elif [ -f "Makefile" ] || [ -f "makefile" ]; then
    # Check if test target exists
    if make -n test &> /dev/null; then
        test_commands+=("make test")
    fi
elif [ -f "pytest.ini" ] || [ -f "setup.cfg" ] || [ -f "tox.ini" ]; then
    # Python project with pytest
    if command -v pytest &> /dev/null; then
        test_commands+=("pytest")
    fi
elif [ -f "setup.py" ] || [ -f "pyproject.toml" ]; then
    # Python project
    if command -v python &> /dev/null; then
        test_commands+=("python -m pytest" "python -m unittest discover")
    fi
fi

# Remove duplicates
test_commands=($(printf "%s\n" "${test_commands[@]}" | sort -u))

# Function to run a test command
run_test_command() {
    local cmd="$1"
    local output
    local exit_code
    
    echo "Running: $cmd" >&2
    
    # Run command and capture output
    if output=$(eval "$cmd" 2>&1); then
        echo "✓ Tests passed: $cmd" >&2
        return 0
    else
        exit_code=$?
        echo "✗ Tests failed: $cmd (exit code: $exit_code)" >&2
        # Extract test failure information
        echo "$output" | grep -E "(FAIL|Failed|failed|Error|ERROR|✗|✖|●)" | head -20 | while IFS= read -r line; do
            errors+=("$line")
        done
        return 1
    fi
}

# Check if any test files exist
test_files_exist=false
for pattern in "*test*" "*spec*" "*Test*" "*Spec*" "tests/" "test/" "__tests__/"; do
    if compgen -G "$pattern" > /dev/null; then
        test_files_exist=true
        break
    fi
done

if [ "$test_files_exist" = false ]; then
    errors+=("No test files found. Please write tests for your code.")
elif [ ${#test_commands[@]} -eq 0 ]; then
    errors+=("No test runner detected. Please configure a test framework.")
else
    # Run test commands
    test_succeeded=false
    for cmd in "${test_commands[@]}"; do
        if run_test_command "$cmd"; then
            test_succeeded=true
            break
        fi
    done
    
    if [ "$test_succeeded" = false ]; then
        errors+=("All test commands failed. Please fix failing tests.")
    fi
fi

# Function to escape JSON strings
json_escape() {
    printf '%s' "$1" | sed 's/\\/\\\\/g; s/"/\\"/g; s/	/\\t/g; s/
/\\n/g; s//\\r/g'
}

# Output results in JSON format
echo "{"
echo "  \"passed\": $([ ${#errors[@]} -eq 0 ] && echo "true" || echo "false"),"
echo "  \"errors\": ["
if [ ${#errors[@]} -gt 0 ]; then
    for i in "${!errors[@]}"; do
        echo -n "    \"$(json_escape "${errors[$i]}")\"" 
        if [ $i -lt $((${#errors[@]} - 1)) ]; then
            echo ","
        else
            echo
        fi
    done
fi
echo "  ],"
echo "  \"fixInstructions\": \"Fix all failing tests. Ensure all test cases pass before deployment. If no tests exist, write comprehensive test coverage.\""
echo "}"
